Model,Activation,Dataset,Test accuracy,Test loss,Train accuracy,Train loss,Epoch,Learning rate,Weight decay,Optimizer,Neurons,Nlayers,Time
poincare,relu,cifar10,0.2498999983072281,2.0478672981262207,0.22124760230179027,2.1015262308023166,0,0.01,1e-05,sgd,40,4,28.3448429107666
poincare,relu,cifar10,0.4059999883174896,1.6622228622436523,0.3759990409207161,1.7212325732421387,1,0.01,1e-05,sgd,40,4,56.79871225357056
poincare,relu,cifar10,0.40459999442100525,1.65031898021698,0.42838874680306904,1.594882010803808,2,0.01,1e-05,sgd,40,4,85.20565986633301
poincare,relu,cifar10,0.3757999837398529,1.7284849882125854,0.45728101023017903,1.5247789532937053,3,0.01,1e-05,sgd,40,4,114.24478816986084
poincare,relu,cifar10,0.44759997725486755,1.5355126857757568,0.4733056265984655,1.477740409124233,4,0.01,1e-05,sgd,40,4,142.4716136455536
poincare,relu,cifar10,0.4472000002861023,1.546750783920288,0.4874320652173913,1.4376637562156638,5,0.01,1e-05,sgd,40,4,171.0071120262146
poincare,relu,cifar10,0.42890000343322754,1.567373275756836,0.49960038363171355,1.4052153607768476,6,0.01,1e-05,sgd,40,4,199.95038962364197
poincare,relu,cifar10,0.4728999733924866,1.5037709474563599,0.5090712915601023,1.3777770743040783,7,0.01,1e-05,sgd,40,4,228.30762672424316
poincare,relu,cifar10,0.4462999999523163,1.6262218952178955,0.5208799552429667,1.3546913320298695,8,0.01,1e-05,sgd,40,4,256.7646596431732
poincare,relu,cifar10,0.4521999955177307,1.552439570426941,0.5256353900255755,1.3350191239048452,9,0.01,1e-05,sgd,40,4,285.16744017601013
poincare,relu,cifar10,0.45639997720718384,1.5259557962417603,0.5316096547314578,1.3174500575913188,10,0.01,1e-05,sgd,40,4,313.52279472351074
poincare,relu,cifar10,0.47829997539520264,1.490126371383667,0.5384830562659847,1.299046492866238,11,0.01,1e-05,sgd,40,4,341.8833341598511
poincare,relu,cifar10,0.45419999957084656,1.5902771949768066,0.5443773976982097,1.2850717346534095,12,0.01,1e-05,sgd,40,4,370.07766938209534
poincare,relu,cifar10,0.48409998416900635,1.4724923372268677,0.5520300511508951,1.2686076382999225,13,0.01,1e-05,sgd,40,4,398.67568373680115
poincare,relu,cifar10,0.4860000014305115,1.4826130867004395,0.5589434143222506,1.2562939302848124,14,0.01,1e-05,sgd,40,4,427.5531804561615
poincare,relu,cifar10,0.47699999809265137,1.5374963283538818,0.5611812659846548,1.2441693538290155,15,0.01,1e-05,sgd,40,4,456.12614917755127
poincare,relu,cifar10,0.4640999734401703,1.5596249103546143,0.5660166240409207,1.2310153207815517,16,0.01,1e-05,sgd,40,4,484.62490797042847
poincare,relu,cifar10,0.4830999970436096,1.50773286819458,0.5701526534526854,1.2181959124019994,17,0.01,1e-05,sgd,40,4,512.9415237903595
poincare,relu,cifar10,0.47360000014305115,1.5378361940383911,0.5762268222506394,1.2070774355965197,18,0.01,1e-05,sgd,40,4,541.38991522789
poincare,relu,cifar10,0.48339998722076416,1.5147606134414673,0.579363810741688,1.1983443910203626,19,0.01,1e-05,sgd,40,4,569.7106988430023
poincare,relu,cifar10,0.47450000047683716,1.5126975774765015,0.5811421035805626,1.1895575337397777,20,0.01,1e-05,sgd,40,4,598.023190498352
poincare,relu,cifar10,0.49059998989105225,1.4726452827453613,0.5838594948849105,1.1817126102612148,21,0.01,1e-05,sgd,40,4,626.1913447380066
poincare,relu,cifar10,0.4714999794960022,1.5593928098678589,0.589474104859335,1.1718314718407439,22,0.01,1e-05,sgd,40,4,654.4965624809265
poincare,relu,cifar10,0.46859997510910034,1.5675439834594727,0.59065297314578,1.161524263108173,23,0.01,1e-05,sgd,40,4,683.0037250518799
poincare,relu,cifar10,0.4772000014781952,1.5169990062713623,0.5929507672634271,1.1546216724473801,24,0.01,1e-05,sgd,40,4,711.2696180343628
poincare,relu,cifar10,0.4737999737262726,1.5339276790618896,0.5971867007672634,1.1464033485830898,25,0.01,1e-05,sgd,40,4,740.1628270149231
poincare,relu,cifar10,0.47859999537467957,1.518217921257019,0.6020620204603581,1.1369091702239287,26,0.01,1e-05,sgd,40,4,768.4556295871735
poincare,relu,cifar10,0.44849997758865356,1.6363269090652466,0.6062979539641944,1.1262523572310768,27,0.01,1e-05,sgd,40,4,796.7479147911072

Model,Activation,Dataset,Test accuracy,Test loss,Train accuracy,Train loss,Epoch,Learning rate,Weight decay,Optimizer,Neurons,Nlayers,Time
poincare,relu,fmnist,0.8657000064849854,0.3999205529689789,0.9092817164179104,0.2465731923116931,0,0.01,1e-05,sgd,20,2,21.043853282928467
poincare,relu,fmnist,0.8685999512672424,0.401096910238266,0.9098980543710021,0.24611083114706378,1,0.01,1e-05,sgd,20,2,42.335289478302
poincare,relu,fmnist,0.8640999794006348,0.422877699136734,0.910264525586354,0.24553439408334207,2,0.01,1e-05,sgd,20,2,63.61127233505249
poincare,relu,fmnist,0.871399998664856,0.38344237208366394,0.9108975213219617,0.2429765048089312,3,0.01,1e-05,sgd,20,2,84.40654993057251
poincare,relu,fmnist,0.8696999549865723,0.38709521293640137,0.9105810234541578,0.24268936016348633,4,0.01,1e-05,sgd,20,2,105.37961745262146
poincare,relu,fmnist,0.8664999604225159,0.39843136072158813,0.9112639925373134,0.24109578362977835,5,0.01,1e-05,sgd,20,2,126.41269826889038
poincare,relu,fmnist,0.8700999617576599,0.3987508714199066,0.9120802238805971,0.23993858034565632,6,0.01,1e-05,sgd,20,2,147.288889169693
poincare,relu,fmnist,0.8696999549865723,0.39666199684143066,0.9132296108742004,0.23888879758256204,7,0.01,1e-05,sgd,20,2,168.34721755981445
poincare,relu,fmnist,0.8693000078201294,0.40382683277130127,0.9126799040511727,0.2370543569358173,8,0.01,1e-05,sgd,20,2,189.3209638595581
poincare,relu,fmnist,0.873199999332428,0.3858085572719574,0.9126299307036247,0.23699261260820603,9,0.01,1e-05,sgd,20,2,210.42765593528748
poincare,relu,fmnist,0.8776999711990356,0.378449022769928,0.9130796908315565,0.2362687533328147,10,0.01,1e-05,sgd,20,2,231.3254315853119
poincare,relu,fmnist,0.8720999956130981,0.3915151357650757,0.914079157782516,0.23396060316324996,11,0.01,1e-05,sgd,20,2,252.10503840446472
poincare,relu,fmnist,0.8631999492645264,0.41696375608444214,0.9129797441364605,0.23503647696203006,12,0.01,1e-05,sgd,20,2,273.187655210495
poincare,relu,fmnist,0.8700999617576599,0.4013593792915344,0.9144456289978679,0.23278061598777644,13,0.01,1e-05,sgd,20,2,294.08167719841003
poincare,relu,fmnist,0.8704999685287476,0.39253056049346924,0.9149620202558635,0.2322039868213983,14,0.01,1e-05,sgd,20,2,315.14534425735474
poincare,relu,fmnist,0.847000002861023,0.4866931736469269,0.9145289179104478,0.23172538943572848,15,0.01,1e-05,sgd,20,2,336.1646294593811
poincare,relu,fmnist,0.8740999698638916,0.38963085412979126,0.9146954957356077,0.2314663392696172,16,0.01,1e-05,sgd,20,2,357.1653928756714
poincare,relu,fmnist,0.8637999892234802,0.41730669140815735,0.9162280117270789,0.22907597550959474,17,0.01,1e-05,sgd,20,2,378.29373598098755
poincare,relu,fmnist,0.8707999587059021,0.3898424208164215,0.915994802771855,0.2293214500466707,18,0.01,1e-05,sgd,20,2,399.3110795021057
poincare,relu,fmnist,0.8632999658584595,0.4377342164516449,0.9156949626865671,0.22874083049071114,19,0.01,1e-05,sgd,20,2,420.39585757255554
poincare,relu,fmnist,0.8621999621391296,0.41318023204803467,0.9163612739872068,0.22667454683910937,20,0.01,1e-05,sgd,20,2,441.275021314621
poincare,relu,fmnist,0.8673999905586243,0.40514492988586426,0.91792710554371,0.2250693516730309,21,0.01,1e-05,sgd,20,2,462.2370300292969
poincare,relu,fmnist,0.8691999912261963,0.41351816058158875,0.9174440298507462,0.2247459037797347,22,0.01,1e-05,sgd,20,2,483.1997604370117
poincare,relu,fmnist,0.8698999881744385,0.40673360228538513,0.9170109275053305,0.2262472133996136,23,0.01,1e-05,sgd,20,2,504.1074743270874
poincare,relu,fmnist,0.8651999831199646,0.4124488830566406,0.9177438699360341,0.2244198775010259,24,0.01,1e-05,sgd,20,2,525.1940286159515

Model,Activation,Dataset,Test accuracy,Test loss,Train accuracy,Train loss,Epoch,Learning rate,Weight decay,Optimizer,Neurons,Nlayers,Time
poincare,relu,fmnist,0.8675999641418457,0.42852938175201416,0.9448627398720683,0.1516743540319044,0,0.01,1e-05,sgd,100,1,15.54844856262207
poincare,relu,fmnist,0.8722999691963196,0.4103199243545532,0.9464285714285714,0.1483209248302556,1,0.01,1e-05,sgd,100,1,30.991094827651978
poincare,relu,fmnist,0.8784999847412109,0.39382800459861755,0.9464285714285714,0.14660842951808148,2,0.01,1e-05,sgd,100,1,46.34834003448486
poincare,relu,fmnist,0.8628000020980835,0.430711030960083,0.9452791844349681,0.1505446389589562,3,0.01,1e-05,sgd,100,1,61.84002757072449
poincare,relu,fmnist,0.8763999938964844,0.4194197356700897,0.9480110607675906,0.1445483248780118,4,0.01,1e-05,sgd,100,1,77.31074285507202
poincare,relu,fmnist,0.8073999881744385,0.6714149713516235,0.9467950426439232,0.14812298495171547,5,0.01,1e-05,sgd,100,1,92.9377510547638
poincare,relu,fmnist,0.8792999982833862,0.40390896797180176,0.9488606076759062,0.1454889425463768,6,0.01,1e-05,sgd,100,1,108.29659700393677
poincare,relu,fmnist,0.8606999516487122,0.4685998558998108,0.9482609275053305,0.14523137759353752,7,0.01,1e-05,sgd,100,1,123.88745188713074
poincare,relu,fmnist,0.8834999799728394,0.3756251335144043,0.9480277185501066,0.14526885878969867,8,0.01,1e-05,sgd,100,1,139.40744924545288
poincare,relu,fmnist,0.8741999864578247,0.4135585427284241,0.9493769989339019,0.14210459370332867,9,0.01,1e-05,sgd,100,1,154.8932225704193
poincare,relu,fmnist,0.8819999694824219,0.389796644449234,0.9476445895522388,0.1438182142239485,10,0.01,1e-05,sgd,100,1,170.4721372127533
poincare,relu,fmnist,0.8798999786376953,0.405254065990448,0.9495768923240938,0.14298589472998496,11,0.01,1e-05,sgd,100,1,186.0753960609436
poincare,relu,fmnist,0.8810999989509583,0.3812112510204315,0.9481443230277186,0.14373267456484057,12,0.01,1e-05,sgd,100,1,201.80040335655212
poincare,relu,fmnist,0.87909996509552,0.39229804277420044,0.949243736673774,0.14052601575231882,13,0.01,1e-05,sgd,100,1,217.2224931716919
poincare,relu,fmnist,0.8730999827384949,0.41803285479545593,0.9498101012793176,0.13917043867673892,14,0.01,1e-05,sgd,100,1,232.65647196769714
poincare,relu,fmnist,0.878600001335144,0.40780606865882874,0.9501599147121536,0.13916103510674574,15,0.01,1e-05,sgd,100,1,248.34579634666443
poincare,relu,fmnist,0.8797000050544739,0.3913889527320862,0.9488439498933902,0.13938065124814636,16,0.01,1e-05,sgd,100,1,263.80758142471313
poincare,relu,fmnist,0.8762999773025513,0.4089665710926056,0.9490605010660981,0.14123306912916112,17,0.01,1e-05,sgd,100,1,279.2704381942749
poincare,relu,fmnist,0.8835999965667725,0.39720019698143005,0.9498767324093816,0.14211582247096338,18,0.01,1e-05,sgd,100,1,294.70400881767273
poincare,relu,fmnist,0.863599956035614,0.47729820013046265,0.9516424573560768,0.13482632442935508,19,0.01,1e-05,sgd,100,1,310.1294479370117
poincare,relu,fmnist,0.885699987411499,0.3768821358680725,0.9506929637526652,0.1379482737069191,20,0.01,1e-05,sgd,100,1,325.6852903366089
poincare,relu,fmnist,0.8826999664306641,0.3940531611442566,0.9522088219616205,0.13422179309877633,21,0.01,1e-05,sgd,100,1,341.1346592903137
poincare,relu,fmnist,0.819599986076355,0.6964971423149109,0.951059434968017,0.13526624894397124,22,0.01,1e-05,sgd,100,1,356.71441173553467

Model,Activation,Dataset,Test accuracy,Test loss,Train accuracy,Train loss,Epoch,Learning rate,Weight decay,Optimizer,Neurons,Nlayers,Time
poincare,relu,fmnist,0.8794999718666077,0.3713817000389099,0.9323194296375267,0.1838836578973956,0,0.01,1e-05,sgd,100,1,15.481163024902344
poincare,relu,fmnist,0.8751999735832214,0.3778987526893616,0.9332022921108742,0.181753332621412,1,0.01,1e-05,sgd,100,1,31.039631605148315
poincare,relu,fmnist,0.8834999799728394,0.35775789618492126,0.9338852611940298,0.18004706648510022,2,0.01,1e-05,sgd,100,1,46.4015166759491
poincare,relu,fmnist,0.887999951839447,0.3514775335788727,0.9344849413646056,0.1796099377720595,3,0.01,1e-05,sgd,100,1,61.94781494140625
poincare,relu,fmnist,0.8782999515533447,0.36143529415130615,0.9345682302771855,0.1797747528021619,4,0.01,1e-05,sgd,100,1,77.4022889137268
poincare,relu,fmnist,0.8258999586105347,0.5335357785224915,0.9356843017057569,0.17841370829116943,5,0.01,1e-05,sgd,100,1,92.98268008232117
poincare,relu,fmnist,0.8848999738693237,0.35570481419563293,0.9354510927505331,0.17587000852835966,6,0.01,1e-05,sgd,100,1,108.67349147796631
poincare,relu,fmnist,0.8890999555587769,0.34812435507774353,0.9350013326226013,0.17744677037651987,7,0.01,1e-05,sgd,100,1,124.2094373703003
poincare,relu,fmnist,0.8845999836921692,0.35724374651908875,0.9361673773987207,0.17276454398404562,8,0.01,1e-05,sgd,100,1,139.8054769039154
poincare,relu,fmnist,0.8854999542236328,0.363903671503067,0.9369003198294243,0.1722420032388334,9,0.01,1e-05,sgd,100,1,155.30990767478943
poincare,relu,fmnist,0.8743000030517578,0.40567725896835327,0.9375333155650319,0.17351761713091815,10,0.01,1e-05,sgd,100,1,171.02200555801392
poincare,relu,fmnist,0.8757999539375305,0.40189892053604126,0.9386160714285714,0.17036335825967763,11,0.01,1e-05,sgd,100,1,186.31774640083313
poincare,relu,fmnist,0.8787999749183655,0.37803009152412415,0.9371335287846482,0.16964414736418837,12,0.01,1e-05,sgd,100,1,201.666974067688
poincare,relu,fmnist,0.8799999952316284,0.3701053261756897,0.9372667910447762,0.17107594506080342,13,0.01,1e-05,sgd,100,1,217.28952550888062
poincare,relu,fmnist,0.8709999918937683,0.3886156678199768,0.9393656716417911,0.166572529747129,14,0.01,1e-05,sgd,100,1,232.76723313331604
poincare,relu,fmnist,0.7591999769210815,0.9523553848266602,0.9390658315565032,0.16736076404846933,15,0.01,1e-05,sgd,100,1,248.21875071525574
poincare,relu,fmnist,0.883899986743927,0.37136462330818176,0.9386493869936035,0.16800410580287164,16,0.01,1e-05,sgd,100,1,263.68133878707886
poincare,relu,fmnist,0.8798999786376953,0.37803807854652405,0.9390325159914712,0.1653955695646277,17,0.01,1e-05,sgd,100,1,279.0911419391632
poincare,relu,fmnist,0.8769999742507935,0.38952088356018066,0.9397321428571429,0.16384307752802238,18,0.01,1e-05,sgd,100,1,294.76238489151
poincare,relu,fmnist,0.8831999897956848,0.36630308628082275,0.9397821162046909,0.16579329576105006,19,0.01,1e-05,sgd,100,1,310.17197275161743
poincare,relu,fmnist,0.8755999803543091,0.39345332980155945,0.941414578891258,0.16133662521330785,20,0.01,1e-05,sgd,100,1,325.7880997657776
poincare,relu,fmnist,0.8702999949455261,0.4106786549091339,0.9409315031982942,0.16134443555051076,21,0.01,1e-05,sgd,100,1,341.1850001811981

Model,Activation,Dataset,Test accuracy,Test loss,Train accuracy,Train loss,Epoch,Learning rate,Weight decay,Optimizer,Neurons,Nlayers,Time
poincare,relu,fmnist,0.8078999519348145,0.5654106140136719,0.7501332622601279,0.7302470900007149,0,0.01,1e-05,sgd,200,2,21.070624351501465
poincare,relu,fmnist,0.8080999851226807,0.5372275114059448,0.847831156716418,0.42216900486681763,1,0.01,1e-05,sgd,200,2,42.48949980735779
poincare,relu,fmnist,0.8542999625205994,0.41252315044403076,0.8640225213219617,0.3753355061099219,2,0.01,1e-05,sgd,200,2,63.40595746040344
poincare,relu,fmnist,0.8610000014305115,0.39100825786590576,0.8738839285714286,0.3444261879030702,3,0.01,1e-05,sgd,200,2,84.51383996009827
poincare,relu,fmnist,0.857699990272522,0.4113253951072693,0.8812300106609808,0.3231867622973314,4,0.01,1e-05,sgd,200,2,105.4196195602417
poincare,relu,fmnist,0.8561999797821045,0.398397296667099,0.8869602878464818,0.30510497530068414,5,0.01,1e-05,sgd,200,2,126.51342606544495
poincare,relu,fmnist,0.8728999495506287,0.3579084575176239,0.8928904584221748,0.29040657932252517,6,0.01,1e-05,sgd,200,2,147.38622117042542
poincare,relu,fmnist,0.8762999773025513,0.34788334369659424,0.8970215884861408,0.2781398939187211,7,0.01,1e-05,sgd,200,2,168.34336400032043
poincare,relu,fmnist,0.8605999946594238,0.4005141258239746,0.9015691631130064,0.2663620113611603,8,0.01,1e-05,sgd,200,2,189.57932424545288
poincare,relu,fmnist,0.8720999956130981,0.3623236417770386,0.9045509061833689,0.2568008587447438,9,0.01,1e-05,sgd,200,2,210.6200089454651
poincare,relu,fmnist,0.828499972820282,0.45519593358039856,0.9087320095948828,0.24612777467682037,10,0.01,1e-05,sgd,200,2,231.78238654136658
poincare,relu,fmnist,0.882599949836731,0.33443140983581543,0.9104644189765458,0.2367187740007189,11,0.01,1e-05,sgd,200,2,252.7488498687744
poincare,relu,fmnist,0.8783999681472778,0.3523886203765869,0.9133462153518124,0.2306187195079858,12,0.01,1e-05,sgd,200,2,273.7953476905823
poincare,relu,fmnist,0.8851000070571899,0.33890289068222046,0.9175939498933902,0.22169623158967444,13,0.01,1e-05,sgd,200,2,295.3087990283966
poincare,relu,fmnist,0.8788999915122986,0.34575173258781433,0.9186600479744137,0.2156528272449589,14,0.01,1e-05,sgd,200,2,316.28414368629456
poincare,relu,fmnist,0.8788999915122986,0.3491891324520111,0.9229910714285714,0.2067425783906283,15,0.01,1e-05,sgd,200,2,337.4103660583496
poincare,relu,fmnist,0.8834999799728394,0.3455759882926941,0.9244569562899787,0.20107850775932834,16,0.01,1e-05,sgd,200,2,358.4549527168274
poincare,relu,fmnist,0.8815000057220459,0.35756587982177734,0.9268889925373134,0.19446999098319234,17,0.01,1e-05,sgd,200,2,379.3205392360687
poincare,relu,fmnist,0.8797000050544739,0.3694137930870056,0.9282549307036247,0.18883770198297145,18,0.01,1e-05,sgd,200,2,400.8246684074402
poincare,relu,fmnist,0.8847000002861023,0.35059666633605957,0.931686433901919,0.18343890666056162,19,0.01,1e-05,sgd,200,2,421.8236873149872
poincare,relu,fmnist,0.8845999836921692,0.35696685314178467,0.9333855277185501,0.180091416880266,20,0.01,1e-05,sgd,200,2,442.8971176147461
poincare,relu,fmnist,0.8557999730110168,0.4507346749305725,0.9345848880597015,0.17430569694192807,21,0.01,1e-05,sgd,200,2,463.85272240638733
poincare,relu,fmnist,0.8733999729156494,0.3893849849700928,0.9357675906183369,0.17018005293585473,22,0.01,1e-05,sgd,200,2,484.9125306606293
poincare,relu,fmnist,0.8720999956130981,0.39403635263442993,0.9389825426439232,0.16301877888491445,23,0.01,1e-05,sgd,200,2,505.9216718673706
poincare,relu,fmnist,0.8823999762535095,0.38089194893836975,0.9411813699360341,0.15942365194220087,24,0.01,1e-05,sgd,200,2,526.945972442627
poincare,relu,fmnist,0.8898999691009521,0.351754367351532,0.9402318763326226,0.16039837104504678,25,0.01,1e-05,sgd,200,2,548.1304934024811

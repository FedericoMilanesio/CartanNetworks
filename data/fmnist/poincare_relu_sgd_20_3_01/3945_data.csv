Model,Activation,Dataset,Test accuracy,Test loss,Train accuracy,Train loss,Epoch,Learning rate,Weight decay,Optimizer,Neurons,Nlayers,Time
poincare,relu,fmnist,0.7475999593734741,0.6550968289375305,0.681603144989339,0.9212791852033468,0,0.01,1e-05,sgd,20,3,26.644213914871216
poincare,relu,fmnist,0.8080999851226807,0.5536379814147949,0.8356709754797441,0.46404636084143797,1,0.01,1e-05,sgd,20,3,53.292048931121826
poincare,relu,fmnist,0.8443999886512756,0.4546966254711151,0.8526952292110874,0.4139722900222868,2,0.01,1e-05,sgd,20,3,79.71676874160767
poincare,relu,fmnist,0.85589998960495,0.41708123683929443,0.8607409381663113,0.3884709009102413,3,0.01,1e-05,sgd,20,3,106.17260241508484
poincare,relu,fmnist,0.8517000079154968,0.4228443503379822,0.8677538646055437,0.36807511384680325,4,0.01,1e-05,sgd,20,3,132.66573214530945
poincare,relu,fmnist,0.8565999865531921,0.40723109245300293,0.8712853144989339,0.3547196377044929,5,0.01,1e-05,sgd,20,3,159.29877924919128
poincare,relu,fmnist,0.8667999505996704,0.38842660188674927,0.8765158582089553,0.3419851971460558,6,0.01,1e-05,sgd,20,3,185.883868932724
poincare,relu,fmnist,0.8292999863624573,0.5110232830047607,0.8799640191897654,0.3342896385042906,7,0.01,1e-05,sgd,20,3,212.34782433509827
poincare,relu,fmnist,0.8215999603271484,0.5466658473014832,0.8816464552238806,0.32608752162344673,8,0.01,1e-05,sgd,20,3,238.90140557289124
poincare,relu,fmnist,0.849399983882904,0.43447303771972656,0.8826625799573561,0.3202841082996905,9,0.01,1e-05,sgd,20,3,265.496618270874
poincare,relu,fmnist,0.8601999878883362,0.3978690803050995,0.8861273987206824,0.31330808544400407,10,0.01,1e-05,sgd,20,3,291.9493935108185
poincare,relu,fmnist,0.864799976348877,0.3905409276485443,0.8878598081023454,0.30736309200970097,11,0.01,1e-05,sgd,20,3,318.53837752342224
poincare,relu,fmnist,0.8655999898910522,0.38247358798980713,0.8890425106609808,0.3024604271914659,12,0.01,1e-05,sgd,20,3,344.9040927886963
poincare,relu,fmnist,0.8685999512672424,0.3777472972869873,0.8897754530916845,0.2990480815884528,13,0.01,1e-05,sgd,20,3,371.6750178337097
poincare,relu,fmnist,0.8657999634742737,0.3813938498497009,0.8916411247334755,0.294140387167618,14,0.01,1e-05,sgd,20,3,397.8851430416107
poincare,relu,fmnist,0.8675999641418457,0.3867272436618805,0.8937733208955224,0.290294612537442,15,0.01,1e-05,sgd,20,3,424.25822854042053
poincare,relu,fmnist,0.8662999868392944,0.38018858432769775,0.8938899253731343,0.28727296060288765,16,0.01,1e-05,sgd,20,3,450.7980306148529
poincare,relu,fmnist,0.8668999671936035,0.3829457461833954,0.8951725746268657,0.28492292467909835,17,0.01,1e-05,sgd,20,3,477.64206862449646
poincare,relu,fmnist,0.8669999837875366,0.38690245151519775,0.896471881663113,0.28118956136678075,18,0.01,1e-05,sgd,20,3,504.45652747154236
poincare,relu,fmnist,0.8686999678611755,0.38315263390541077,0.8978045042643923,0.27803945172030026,19,0.01,1e-05,sgd,20,3,530.996871471405
poincare,relu,fmnist,0.8651999831199646,0.38482415676116943,0.8996202025586354,0.27489609464304027,20,0.01,1e-05,sgd,20,3,557.4398469924927
poincare,relu,fmnist,0.8655999898910522,0.38585060834884644,0.8997201492537313,0.27123357200705167,21,0.01,1e-05,sgd,20,3,584.1562814712524
poincare,relu,fmnist,0.8652999997138977,0.3939867317676544,0.9001365938166311,0.27095675901738187,22,0.01,1e-05,sgd,20,3,610.6298277378082
poincare,relu,fmnist,0.863099992275238,0.39768871665000916,0.9020022654584222,0.26840998472244754,23,0.01,1e-05,sgd,20,3,637.1889171600342
poincare,relu,fmnist,0.8455999493598938,0.46120840311050415,0.9028851279317697,0.2647662007732432,24,0.01,1e-05,sgd,20,3,663.7646081447601
poincare,relu,fmnist,0.8640999794006348,0.39790788292884827,0.9031016791044776,0.2645483206806661,25,0.01,1e-05,sgd,20,3,690.237330198288
poincare,relu,fmnist,0.8677999973297119,0.39552175998687744,0.904467617270789,0.26065783417110505,26,0.01,1e-05,sgd,20,3,716.6731088161469
poincare,relu,fmnist,0.8671999573707581,0.3874727785587311,0.9046175373134329,0.2590521974310374,27,0.01,1e-05,sgd,20,3,743.1554741859436

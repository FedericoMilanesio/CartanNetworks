Model,Activation,Dataset,Test accuracy,Test loss,Train accuracy,Train loss,Epoch,Learning rate,Weight decay,Optimizer,Neurons,Nlayers,Time
poincare,relu,fmnist,0.8202999830245972,0.49547475576400757,0.7194329690831557,0.8585368576112078,0,0.01,1e-05,sgd,200,3,26.52845859527588
poincare,relu,fmnist,0.847000002861023,0.42503291368484497,0.8480477078891258,0.41907549616116196,1,0.01,1e-05,sgd,200,3,53.21690368652344
poincare,relu,fmnist,0.8343999981880188,0.460711807012558,0.8648220948827292,0.36666928593919224,2,0.01,1e-05,sgd,200,3,79.93406367301941
poincare,relu,fmnist,0.8642999529838562,0.3694930672645569,0.8788146321961621,0.33537003820511835,3,0.01,1e-05,sgd,200,3,106.3238422870636
poincare,relu,fmnist,0.8163999915122986,0.515163779258728,0.8845449093816631,0.3120144945440262,4,0.01,1e-05,sgd,200,3,133.02596879005432
poincare,relu,fmnist,0.8616999983787537,0.3775474727153778,0.8911913646055437,0.29395425179079654,5,0.01,1e-05,sgd,200,3,159.6432123184204
poincare,relu,fmnist,0.8596000075340271,0.38962677121162415,0.896438566098081,0.27920135294101134,6,0.01,1e-05,sgd,200,3,186.20347023010254
poincare,relu,fmnist,0.8748999834060669,0.34871503710746765,0.9014025852878464,0.26620266798621556,7,0.01,1e-05,sgd,200,3,213.28284239768982
poincare,relu,fmnist,0.8830999732017517,0.3362468481063843,0.9052005597014925,0.2539350349050976,8,0.01,1e-05,sgd,200,3,239.8884813785553
poincare,relu,fmnist,0.8676999807357788,0.37706470489501953,0.9092817164179104,0.24412411921568264,9,0.01,1e-05,sgd,200,3,266.55649065971375
poincare,relu,fmnist,0.8818999528884888,0.3451954424381256,0.9120302505330491,0.23470046562649038,10,0.01,1e-05,sgd,200,3,292.9850742816925
poincare,relu,fmnist,0.8788999915122986,0.3493511378765106,0.9160947494669509,0.22508088320589015,11,0.01,1e-05,sgd,200,3,319.62482810020447
poincare,relu,fmnist,0.8831999897956848,0.33171769976615906,0.917793843283582,0.21814567020643494,12,0.01,1e-05,sgd,200,3,346.15496039390564
poincare,relu,fmnist,0.8786999583244324,0.34782302379608154,0.9214752132196162,0.20873599209939875,13,0.01,1e-05,sgd,200,3,372.7119872570038
poincare,relu,fmnist,0.8810999989509583,0.36492297053337097,0.9245569029850746,0.20098449823174522,14,0.01,1e-05,sgd,200,3,399.33767199516296
poincare,relu,fmnist,0.8842999935150146,0.354776531457901,0.9271388592750534,0.19393850098064205,15,0.01,1e-05,sgd,200,3,425.6194987297058
poincare,relu,fmnist,0.8849999904632568,0.3521612584590912,0.9294542910447762,0.1865696683109029,16,0.01,1e-05,sgd,200,3,452.1044702529907
poincare,relu,fmnist,0.8784999847412109,0.38857221603393555,0.9320362473347548,0.1799872456841282,17,0.01,1e-05,sgd,200,3,478.7709991931915
poincare,relu,fmnist,0.8876999616622925,0.3469720184803009,0.9343350213219617,0.17592973510291912,18,0.01,1e-05,sgd,200,3,505.328955411911
poincare,relu,fmnist,0.8833000063896179,0.3737189769744873,0.9361507196162047,0.16950960338377813,19,0.01,1e-05,sgd,200,3,532.128324508667
poincare,relu,fmnist,0.8836999535560608,0.36994796991348267,0.9373167643923241,0.16468564629840698,20,0.01,1e-05,sgd,200,3,558.723640203476
poincare,relu,fmnist,0.8671999573707581,0.4317704141139984,0.9389992004264393,0.16102518830329243,21,0.01,1e-05,sgd,200,3,585.3780872821808
poincare,relu,fmnist,0.880299985408783,0.3819669485092163,0.9418809968017058,0.15365177041678224,22,0.01,1e-05,sgd,200,3,611.9360625743866
poincare,relu,fmnist,0.8892999887466431,0.3602794408798218,0.9438965884861408,0.14828895327092997,23,0.01,1e-05,sgd,200,3,638.4869170188904
poincare,relu,fmnist,0.8847999572753906,0.3814827501773834,0.9456456556503199,0.14617195543346564,24,0.01,1e-05,sgd,200,3,665.1962757110596
poincare,relu,fmnist,0.8823999762535095,0.38041016459465027,0.9465618336886994,0.1406382254438042,25,0.01,1e-05,sgd,200,3,691.7903199195862
poincare,relu,fmnist,0.877299964427948,0.45036473870277405,0.9487606609808102,0.13515965114119274,26,0.01,1e-05,sgd,200,3,718.4387319087982
